//! Per-node tokio task with independent event loop.
//!
//! Each node runs in its own tokio task, processing events from:
//! - Network messages (from other nodes via router)
//! - Timers (via DelayQueue)
//! - Internal events (from EnqueueInternal actions)
//! - Transaction submissions (from orchestrator)
//!
//! The event loop uses `biased` select to prioritize internal events over
//! external ones, matching the deterministic simulator's priority semantics.

use crate::metrics::{MetricsEvent, MetricsTx};
use crate::router::{Destination, InboundMessage, NodeRx, RoutedMessage, RouterTx};
use futures::StreamExt;
use hyperscale_core::{Action, Event, StateMachine, TimerId};
use hyperscale_node::NodeStateMachine;
use hyperscale_production::ThreadPoolManager;
use hyperscale_simulation::SimStorage;
use hyperscale_types::{Hash, PartitionNumber, PublicKey, Signature};
use std::collections::HashMap;
use std::sync::Arc;
use std::time::Instant;
use tokio::sync::{mpsc, oneshot};
use tokio_util::time::{delay_queue, DelayQueue};

/// Handle for controlling a node task.
pub struct NodeHandle {
    /// Sender for submitting transactions.
    pub tx_submit: mpsc::Sender<Event>,
    /// Shutdown signal.
    pub shutdown: oneshot::Sender<()>,
}

/// Configuration for a node task.
pub struct NodeTaskConfig {
    pub node_index: u32,
    pub state_machine: NodeStateMachine,
    pub storage: SimStorage,
    pub message_rx: NodeRx,
    pub router_tx: RouterTx,
    pub thread_pools: Arc<ThreadPoolManager>,
    pub metrics_tx: MetricsTx,
    /// Initial actions from genesis initialization (timers, etc.)
    pub initial_actions: Vec<hyperscale_core::Action>,
}

/// Runs a single node in its own tokio task.
pub struct NodeTask {
    node_index: u32,
    state: NodeStateMachine,
    storage: SimStorage,
    message_rx: NodeRx,
    router_tx: RouterTx,
    thread_pools: Arc<ThreadPoolManager>,
    metrics_tx: MetricsTx,

    /// Timer queue - yields timer IDs when they're due.
    timers: DelayQueue<TimerId>,
    /// Map timer_id -> delay_queue key for cancellation.
    timer_keys: HashMap<TimerId, delay_queue::Key>,

    /// Internal event channel (for EnqueueInternal actions and async callbacks).
    /// Unbounded since internal events are generated by this node's own state machine
    /// and bounded by protocol flow (e.g., number of pending verifications).
    internal_tx: mpsc::UnboundedSender<Event>,
    internal_rx: mpsc::UnboundedReceiver<Event>,

    /// Transaction submission receiver.
    tx_submit_rx: mpsc::Receiver<Event>,

    /// Shutdown receiver.
    shutdown_rx: oneshot::Receiver<()>,

    /// Start time for elapsed time calculation.
    start_time: Instant,

    /// Initial actions from genesis (processed once on startup).
    initial_actions: Vec<hyperscale_core::Action>,
}

impl NodeTask {
    /// Create a new node task.
    pub fn new(config: NodeTaskConfig) -> (Self, NodeHandle) {
        let (tx_submit, tx_submit_rx) = mpsc::channel(1000);
        let (shutdown_tx, shutdown_rx) = oneshot::channel();
        let (internal_tx, internal_rx) = mpsc::unbounded_channel();

        let task = Self {
            node_index: config.node_index,
            state: config.state_machine,
            storage: config.storage,
            message_rx: config.message_rx,
            router_tx: config.router_tx,
            thread_pools: config.thread_pools,
            metrics_tx: config.metrics_tx,
            timers: DelayQueue::new(),
            timer_keys: HashMap::new(),
            internal_tx,
            internal_rx,
            tx_submit_rx,
            shutdown_rx,
            start_time: Instant::now(),
            initial_actions: config.initial_actions,
        };

        let handle = NodeHandle {
            tx_submit,
            shutdown: shutdown_tx,
        };

        (task, handle)
    }

    /// Get the node index.
    pub fn node_index(&self) -> u32 {
        self.node_index
    }

    /// Run the node's event loop.
    pub async fn run(mut self) {
        // Process initial actions from genesis (sets up proposal/view-change timers)
        let initial_actions = std::mem::take(&mut self.initial_actions);
        for action in initial_actions {
            self.execute_action(action).await;
        }

        loop {
            tokio::select! {
                biased;

                // Shutdown signal (highest priority)
                _ = &mut self.shutdown_rx => {
                    tracing::debug!(node = self.node_index, "Node shutting down");
                    break;
                }

                // Internal events (priority over external - matches deterministic simulator)
                Some(event) = self.internal_rx.recv() => {
                    self.handle_event(event).await;
                }

                // Timer fired
                Some(expired) = self.timers.next() => {
                    let timer_id = expired.into_inner();
                    self.timer_keys.remove(&timer_id);
                    let event = Self::timer_to_event(timer_id);
                    self.handle_event(event).await;
                }

                // Inbound messages from other nodes
                Some(msg) = self.message_rx.recv() => {
                    self.handle_inbound_message(msg).await;
                }

                // Transaction submissions
                Some(event) = self.tx_submit_rx.recv() => {
                    self.handle_event(event).await;
                }
            }
        }
    }

    /// Convert timer ID to event.
    fn timer_to_event(id: TimerId) -> Event {
        match id {
            TimerId::Proposal => Event::ProposalTimer,
            TimerId::ViewChange => Event::ViewChangeTimer,
            TimerId::Cleanup => Event::CleanupTimer,
        }
    }

    /// Handle an inbound message from another node.
    async fn handle_inbound_message(&mut self, msg: InboundMessage) {
        // Use the shared conversion method from OutboundMessage
        let event = msg.message.to_received_event();
        self.handle_event(event).await;
    }

    /// Process an event through the state machine.
    async fn handle_event(&mut self, event: Event) {
        // Update time (each node has independent elapsed time)
        let elapsed = self.start_time.elapsed();
        self.state.set_time(elapsed);

        // Process through state machine
        let actions = self.state.handle(event);

        // Execute actions
        for action in actions {
            self.execute_action(action).await;
        }
    }

    /// Verify aggregated signature using the simulation runner's approach.
    fn verify_aggregated_signature(
        signer_keys: &[PublicKey],
        message: &[u8],
        signature: &Signature,
    ) -> bool {
        if signer_keys.is_empty() {
            // No signers - valid only if it's a zero signature (single-shard case)
            *signature == Signature::zero()
        } else {
            // Aggregate the public keys and verify
            match PublicKey::aggregate_bls(signer_keys) {
                Ok(aggregated_pk) => aggregated_pk.verify(message, signature),
                Err(_) => false,
            }
        }
    }

    /// Execute an action from the state machine.
    pub async fn execute_action(&mut self, action: Action) {
        match action {
            Action::BroadcastToShard { shard, message } => {
                // Use try_send to avoid blocking the node task if channel is full
                let _ = self.router_tx.try_send(RoutedMessage {
                    from: self.node_index,
                    destination: Destination::Shard(shard),
                    message: Arc::new(message),
                });
            }

            Action::BroadcastGlobal { message } => {
                // Use try_send to avoid blocking the node task if channel is full
                let _ = self.router_tx.try_send(RoutedMessage {
                    from: self.node_index,
                    destination: Destination::Global,
                    message: Arc::new(message),
                });
            }

            Action::SetTimer { id, duration } => {
                // Cancel existing timer with same ID if present
                if let Some(key) = self.timer_keys.remove(&id) {
                    self.timers.remove(&key);
                }
                // Insert new timer
                let key = self.timers.insert(id, duration);
                self.timer_keys.insert(id, key);
            }

            Action::CancelTimer { id } => {
                if let Some(key) = self.timer_keys.remove(&id) {
                    self.timers.remove(&key);
                }
            }

            Action::EnqueueInternal { event } => {
                // Send to internal channel (unbounded, so this won't block)
                let _ = self.internal_tx.send(event);
            }

            // Transaction status updates - report to orchestrator for metrics
            Action::EmitTransactionStatus { tx_hash, status } => {
                if status.is_final() {
                    let _ = self
                        .metrics_tx
                        .try_send(MetricsEvent::TransactionCompleted {
                            hash: tx_hash,
                            status,
                        });
                }
            }

            // Signature verification - offload to crypto thread pool
            Action::VerifyVoteSignature {
                vote,
                public_key,
                signing_message,
            } => {
                let internal_tx = self.internal_tx.clone();
                self.thread_pools.spawn_crypto(move || {
                    let valid = public_key.verify(&signing_message, &vote.signature);
                    let _ = internal_tx.send(Event::VoteSignatureVerified { vote, valid });
                });
            }

            Action::VerifyProvisionSignature {
                provision,
                public_key,
            } => {
                let internal_tx = self.internal_tx.clone();
                self.thread_pools.spawn_crypto(move || {
                    let msg = provision.signing_message();
                    let valid = public_key.verify(&msg, &provision.signature);
                    let _ =
                        internal_tx.send(Event::ProvisionSignatureVerified { provision, valid });
                });
            }

            Action::VerifyStateVoteSignature { vote, public_key } => {
                let internal_tx = self.internal_tx.clone();
                self.thread_pools.spawn_crypto(move || {
                    let msg = vote.signing_message();
                    let valid = public_key.verify(&msg, &vote.signature);
                    let _ = internal_tx.send(Event::StateVoteSignatureVerified { vote, valid });
                });
            }

            Action::VerifyStateCertificateSignature {
                certificate,
                public_keys,
            } => {
                let internal_tx = self.internal_tx.clone();
                self.thread_pools.spawn_crypto(move || {
                    let msg = certificate.signing_message();
                    let signer_keys: Vec<_> = public_keys
                        .iter()
                        .enumerate()
                        .filter(|(i, _)| certificate.signers.is_set(*i))
                        .map(|(_, pk)| pk.clone())
                        .collect();
                    let valid = Self::verify_aggregated_signature(
                        &signer_keys,
                        &msg,
                        &certificate.aggregated_signature,
                    );
                    let _ = internal_tx
                        .send(Event::StateCertificateSignatureVerified { certificate, valid });
                });
            }

            Action::VerifyQcSignature {
                qc,
                public_keys,
                block_hash,
                signing_message,
            } => {
                let internal_tx = self.internal_tx.clone();
                self.thread_pools.spawn_crypto(move || {
                    let signer_keys: Vec<_> = public_keys
                        .iter()
                        .enumerate()
                        .filter(|(i, _)| qc.signers.is_set(*i))
                        .map(|(_, pk)| pk.clone())
                        .collect();
                    let valid = if signer_keys.is_empty() {
                        false
                    } else {
                        match PublicKey::aggregate_bls(&signer_keys) {
                            Ok(aggregated_pk) => {
                                aggregated_pk.verify(&signing_message, &qc.aggregated_signature)
                            }
                            Err(_) => false,
                        }
                    };
                    let _ = internal_tx.send(Event::QcSignatureVerified { block_hash, valid });
                });
            }

            Action::VerifyViewChangeVoteSignature {
                vote,
                public_key,
                signing_message,
            } => {
                let internal_tx = self.internal_tx.clone();
                self.thread_pools.spawn_crypto(move || {
                    let valid = public_key.verify(&signing_message, &vote.signature);
                    let _ =
                        internal_tx.send(Event::ViewChangeVoteSignatureVerified { vote, valid });
                });
            }

            Action::VerifyViewChangeHighestQc {
                vote,
                public_keys,
                signing_message,
            } => {
                let internal_tx = self.internal_tx.clone();
                self.thread_pools.spawn_crypto(move || {
                    let signer_keys: Vec<_> = public_keys
                        .iter()
                        .enumerate()
                        .filter(|(i, _)| vote.highest_qc.signers.is_set(*i))
                        .map(|(_, pk)| pk.clone())
                        .collect();
                    let valid = if signer_keys.is_empty() {
                        // Genesis QC has no signatures
                        vote.highest_qc.is_genesis()
                    } else {
                        match PublicKey::aggregate_bls(&signer_keys) {
                            Ok(aggregated_pk) => aggregated_pk
                                .verify(&signing_message, &vote.highest_qc.aggregated_signature),
                            Err(_) => false,
                        }
                    };
                    let _ = internal_tx.send(Event::ViewChangeHighestQcVerified { vote, valid });
                });
            }

            Action::VerifyViewChangeCertificateSignature {
                certificate,
                public_keys,
                signing_message,
            } => {
                let internal_tx = self.internal_tx.clone();
                self.thread_pools.spawn_crypto(move || {
                    let signer_keys: Vec<_> = public_keys
                        .iter()
                        .enumerate()
                        .filter(|(i, _)| certificate.signers.is_set(*i))
                        .map(|(_, pk)| pk.clone())
                        .collect();
                    let valid = Self::verify_aggregated_signature(
                        &signer_keys,
                        &signing_message,
                        &certificate.aggregated_signature,
                    );
                    let _ = internal_tx
                        .send(Event::ViewChangeCertificateSignatureVerified { certificate, valid });
                });
            }

            // Transaction execution - inline synchronous (storage owned by this task)
            // Note: Execution is READ-ONLY. State writes are in the results.
            Action::ExecuteTransactions {
                block_hash,
                transactions,
                ..
            } => {
                // For now, just return success results - full execution would require RadixExecutor
                let results = transactions
                    .iter()
                    .map(|tx| hyperscale_types::ExecutionResult {
                        transaction_hash: tx.hash(),
                        success: true,
                        state_root: Hash::ZERO,
                        writes: vec![],
                        error: None,
                    })
                    .collect();
                let _ = self.internal_tx.send(Event::TransactionsExecuted {
                    block_hash,
                    results,
                });
            }

            Action::ExecuteCrossShardTransaction { tx_hash, .. } => {
                // Simplified: return success
                let result = hyperscale_types::ExecutionResult {
                    transaction_hash: tx_hash,
                    success: true,
                    state_root: Hash::ZERO,
                    writes: vec![],
                    error: None,
                };
                let _ = self
                    .internal_tx
                    .send(Event::CrossShardTransactionExecuted { tx_hash, result });
            }

            Action::ComputeMerkleRoot { tx_hash, .. } => {
                // Simplified: compute a basic merkle root
                let root = Hash::ZERO; // In production, would compute actual merkle root
                let _ = self
                    .internal_tx
                    .send(Event::MerkleRootComputed { tx_hash, root });
            }

            // Storage actions
            Action::PersistBlock { block, qc } => {
                let height = block.header.height;
                self.storage.put_block(height, block, qc);
            }

            Action::PersistTransactionCertificate { certificate } => {
                // Extract writes for the local shard and commit
                let local_shard = self.state.shard();
                if let Some((_, proof)) = certificate
                    .shard_proofs
                    .iter()
                    .find(|(shard, _)| **shard == local_shard)
                {
                    self.storage
                        .commit_certificate_with_writes(&certificate, &proof.state_writes);
                } else {
                    // No writes for this shard, just store certificate
                    self.storage
                        .put_certificate(certificate.transaction_hash, certificate);
                }
            }

            Action::PersistOwnVote {
                height,
                round,
                block_hash,
            } => {
                self.storage.put_own_vote(height.0, round, block_hash);
            }

            // Storage read actions - respond with callback events
            Action::FetchStateEntries { tx_hash, nodes } => {
                use hyperscale_engine::SubstateStore;
                let entries: Vec<_> = nodes
                    .iter()
                    .flat_map(|node_id| {
                        self.storage
                            .list_substates_for_node(node_id)
                            .map(
                                |(partition, sort_key, value)| hyperscale_types::StateEntry {
                                    node_id: *node_id,
                                    partition: PartitionNumber(partition),
                                    sort_key: sort_key.0,
                                    value: Some(value),
                                },
                            )
                            .collect::<Vec<_>>()
                    })
                    .collect();
                let _ = self
                    .internal_tx
                    .send(Event::StateEntriesFetched { tx_hash, entries });
            }

            Action::FetchBlock { height } => {
                let block = self.storage.get_block(height).map(|(b, _)| b);
                let _ = self.internal_tx.send(Event::BlockFetched { height, block });
            }

            Action::FetchChainMetadata => {
                let height = self.storage.committed_height();
                let (hash, qc) = self
                    .storage
                    .get_block(height)
                    .map(|(b, q)| (Some(b.hash()), Some(q)))
                    .unwrap_or((None, None));
                let _ = self
                    .internal_tx
                    .send(Event::ChainMetadataFetched { height, hash, qc });
            }

            // Emit committed block - informational, just log
            Action::EmitCommittedBlock { block } => {
                tracing::debug!(
                    node = self.node_index,
                    height = block.header.height.0,
                    "Block committed"
                );
            }
        }
    }
}
